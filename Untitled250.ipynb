{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2050b03-8de5-4c9b-8684-18d94721026b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Loading dataset...\n",
      "[INFO] Shape: (5200, 51)\n",
      "[INFO] Columns: ['Age', 'Gender', 'Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'nausea', 'joint_pain', 'abdominal_pain', 'high_fever', 'chills', 'fatigue', 'runny_nose', 'pain_behind_the_eyes', 'dizziness', 'headache', 'chest_pain', 'vomiting', 'cough', 'shivering', 'asthma_history', 'high_cholesterol', 'diabetes', 'obesity', 'hiv_aids', 'nasal_polyps', 'asthma', 'high_blood_pressure', 'severe_headache', 'weakness', 'trouble_seeing', 'fever', 'body_aches', 'sore_throat', 'sneezing', 'diarrhea', 'rapid_breathing', 'rapid_heart_rate', 'pain_behind_eyes', 'swollen_glands', 'rashes', 'sinus_headache', 'facial_pain', 'shortness_of_breath', 'reduced_smell_and_taste', 'skin_irritation', 'itchiness', 'throbbing_headache', 'confusion', 'back_pain', 'knee_ache', 'prognosis']\n",
      "[INFO] Scaler saved at: C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\\gwo_hho_medican_scaler.pkl\n",
      "[INFO] Running Hybrid GWO + HHO optimization...\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "33/33 [==============================] - 1s 4ms/step\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 9ms/step\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "33/33 [==============================] - 1s 5ms/step\n",
      "33/33 [==============================] - 1s 12ms/step\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "[INFO] Iter 1/4 | Best MSE: 0.013680\n",
      "33/33 [==============================] - 1s 5ms/step\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 5ms/step\n",
      "[INFO] Iter 2/4 | Best MSE: 0.013680\n",
      "33/33 [==============================] - 1s 8ms/step\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 5ms/step\n",
      "33/33 [==============================] - 1s 11ms/step\n",
      "[INFO] Iter 3/4 | Best MSE: 0.013680\n",
      "33/33 [==============================] - 1s 8ms/step\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "33/33 [==============================] - 1s 4ms/step\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "[INFO] Iter 4/4 | Best MSE: 0.013678\n",
      "[INFO] Best Parameters (lr, dropout, lstm_units): [8.13288284e-04 1.38031186e-01 6.61670596e+01]\n",
      "[INFO] Best MSE: 0.013678\n",
      "Epoch 1/40\n",
      "104/104 [==============================] - 4s 21ms/step - loss: 0.0269 - val_loss: 0.0208\n",
      "Epoch 2/40\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0197 - val_loss: 0.0174\n",
      "Epoch 3/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0176 - val_loss: 0.0161\n",
      "Epoch 4/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0160 - val_loss: 0.0154\n",
      "Epoch 5/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0149 - val_loss: 0.0143\n",
      "Epoch 6/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 7/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 8/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 9/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 10/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 11/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 12/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 13/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0120 - val_loss: 0.0132\n",
      "Epoch 14/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 15/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 16/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 17/40\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 18/40\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0114 - val_loss: 0.0151\n",
      "Epoch 19/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 20/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 21/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0105 - val_loss: 0.0142\n",
      "Epoch 22/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0107 - val_loss: 0.0156\n",
      "Epoch 23/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 24/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 25/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 26/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 27/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 28/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 29/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0107 - val_loss: 0.0154\n",
      "Epoch 30/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0108 - val_loss: 0.0140\n",
      "Epoch 31/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0107 - val_loss: 0.0140\n",
      "Epoch 32/40\n",
      "104/104 [==============================] - 2s 18ms/step - loss: 0.0104 - val_loss: 0.0145\n",
      "Epoch 33/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0106 - val_loss: 0.0145\n",
      "Epoch 34/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0104 - val_loss: 0.0143\n",
      "Epoch 35/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0099 - val_loss: 0.0141\n",
      "Epoch 36/40\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0096 - val_loss: 0.0149\n",
      "Epoch 37/40\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0101 - val_loss: 0.0149\n",
      "Epoch 38/40\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0102 - val_loss: 0.0148\n",
      "Epoch 39/40\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0098 - val_loss: 0.0155\n",
      "Epoch 40/40\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0102 - val_loss: 0.0163\n",
      "[INFO] Model saved at: C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\\gwo_hho_medican_model.keras\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "[INFO] Metrics: {'MAE': 0.030710658924027273, 'RMSE': 0.12048677171489416, 'R2': 0.6074586392401893}\n",
      "[INFO] Results CSV saved at: C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\\gwo_hho_medican_result.csv\n",
      "[âœ…] All outputs saved successfully in:\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LSTM, Conv1D, MaxPooling1D, Flatten, concatenate\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“‚ Paths\n",
    "# ============================================================\n",
    "base_path = r\"C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\"\n",
    "data_path = os.path.join(base_path, \"archive\", \"Weather-related disease prediction.csv\")\n",
    "\n",
    "model_path = os.path.join(base_path, \"gwo_hho_medican_model.keras\")\n",
    "scaler_path = os.path.join(base_path, \"gwo_hho_medican_scaler.pkl\")\n",
    "yaml_path = os.path.join(base_path, \"gwo_hho_medican_config.yaml\")\n",
    "json_path = os.path.join(base_path, \"gwo_hho_medican_prediction.json\")\n",
    "csv_path = os.path.join(base_path, \"gwo_hho_medican_result.csv\")\n",
    "visual_dir = os.path.join(base_path, \"visuals\")\n",
    "\n",
    "os.makedirs(visual_dir, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“Š Load & Preprocess Data\n",
    "# ============================================================\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "# Keep numeric columns only\n",
    "df = df.select_dtypes(include=[np.number]).dropna()\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "\n",
    "X = scaled[:, :-1]\n",
    "y = scaled[:, -1]\n",
    "\n",
    "# Split data\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Reshape for CNN-LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"[INFO] Scaler saved at: {scaler_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§  CNN-LSTM Model Builder\n",
    "# ============================================================\n",
    "def create_model(params):\n",
    "    lr, dropout, lstm_units = params\n",
    "    inputs = Input(shape=(X_train.shape[1], 1))\n",
    "\n",
    "    cnn = Conv1D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    cnn = MaxPooling1D(pool_size=2)(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "\n",
    "    lstm = LSTM(int(lstm_units), return_sequences=False)(inputs)\n",
    "    merged = concatenate([cnn, lstm])\n",
    "    dense = Dense(64, activation=\"relu\")(merged)\n",
    "    dense = Dropout(dropout)(dense)\n",
    "    output = Dense(1)(dense)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ¦´ Hybrid GWO + HHO Optimizer\n",
    "# ============================================================\n",
    "def objective_function(params):\n",
    "    lr, dropout, lstm_units = params\n",
    "    model = create_model([lr, dropout, lstm_units])\n",
    "    model.fit(X_train, y_train, epochs=8, batch_size=32, verbose=0)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def hybrid_gwo_hho(opt_iters=6, pop_size=4):\n",
    "    print(\"[INFO] Running Hybrid GWO + HHO optimization...\")\n",
    "    lb = [1e-4, 0.1, 16]\n",
    "    ub = [1e-2, 0.5, 128]\n",
    "\n",
    "    wolves = np.random.uniform(lb, ub, (pop_size, len(lb)))\n",
    "    fitness = np.array([objective_function(w) for w in wolves])\n",
    "\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best_wolf = wolves[best_idx].copy()\n",
    "    best_score = fitness[best_idx]\n",
    "\n",
    "    for t in range(opt_iters):\n",
    "        a = 2 - t * (2 / opt_iters)\n",
    "        for i in range(pop_size):\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            A = 2 * a * r1 - a\n",
    "            C = 2 * r2\n",
    "            D = abs(C * best_wolf - wolves[i])\n",
    "            new_pos = best_wolf - A * D\n",
    "\n",
    "            E0 = 2 * np.random.rand() - 1\n",
    "            E = 2 * (1 - (t / opt_iters))\n",
    "            if abs(E) >= 1:\n",
    "                new_pos = np.random.uniform(lb, ub)\n",
    "            else:\n",
    "                jump_strength = 2 * (1 - np.random.rand())\n",
    "                new_pos = best_wolf - E * abs(jump_strength * best_wolf - wolves[i])\n",
    "\n",
    "            new_pos = np.clip(new_pos, lb, ub)\n",
    "            new_fit = objective_function(new_pos)\n",
    "            if new_fit < fitness[i]:\n",
    "                fitness[i] = new_fit\n",
    "                wolves[i] = new_pos\n",
    "            if new_fit < best_score:\n",
    "                best_wolf = new_pos.copy()\n",
    "                best_score = new_fit\n",
    "\n",
    "        print(f\"[INFO] Iter {t+1}/{opt_iters} | Best MSE: {best_score:.6f}\")\n",
    "\n",
    "    return best_wolf, best_score\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§© Run Hybrid Optimization\n",
    "# ============================================================\n",
    "best_params, best_score = hybrid_gwo_hho(opt_iters=4, pop_size=4)\n",
    "print(f\"[INFO] Best Parameters (lr, dropout, lstm_units): {best_params}\")\n",
    "print(f\"[INFO] Best MSE: {best_score:.6f}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§  Final Model Training\n",
    "# ============================================================\n",
    "model = create_model(best_params)\n",
    "history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.2, verbose=1)\n",
    "model.save(model_path)\n",
    "print(f\"[INFO] Model saved at: {model_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“ˆ Evaluation\n",
    "# ============================================================\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Flatten arrays to avoid shape mismatch\n",
    "y_pred = y_pred.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "try:\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "except TypeError:\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "metrics = {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "print(\"[INFO] Metrics:\", metrics)\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"[INFO] Results CSV saved at: {csv_path}\")\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump({\"metrics\": metrics, \"best_params\": [float(x) for x in best_params]}, f, indent=4)\n",
    "\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump({\"optimizer\": \"Hybrid GWO+HHO\", \"best_params\": [float(x) for x in best_params]}, f)\n",
    "\n",
    "# ============================================================\n",
    "# ðŸŽ¨ Visualizations\n",
    "# ============================================================\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.savefig(os.path.join(visual_dir, \"gwo_hho_medican_loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Prediction Comparison\")\n",
    "plt.savefig(os.path.join(visual_dir, \"gwo_hho_medican_comparison_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# âœ… FIXED: flatten arrays before correlation DataFrame\n",
    "corr_df = pd.DataFrame({\n",
    "    \"Actual\": y_test.flatten(),\n",
    "    \"Predicted\": y_pred.flatten()\n",
    "})\n",
    "plt.figure()\n",
    "sns.heatmap(corr_df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.savefig(os.path.join(visual_dir, \"gwo_hho_medican_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"[âœ…] All outputs saved successfully in:\")\n",
    "print(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87db7b6-7ba6-4057-a077-a65489a37e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
