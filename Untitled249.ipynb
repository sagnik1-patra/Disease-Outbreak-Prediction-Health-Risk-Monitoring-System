{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c17f47-cfe6-49b0-9d83-27a3a941feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Loading dataset...\n",
      "[INFO] Shape: (5200, 51)\n",
      "[INFO] Columns: ['Age', 'Gender', 'Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'nausea', 'joint_pain', 'abdominal_pain', 'high_fever', 'chills', 'fatigue', 'runny_nose', 'pain_behind_the_eyes', 'dizziness', 'headache', 'chest_pain', 'vomiting', 'cough', 'shivering', 'asthma_history', 'high_cholesterol', 'diabetes', 'obesity', 'hiv_aids', 'nasal_polyps', 'asthma', 'high_blood_pressure', 'severe_headache', 'weakness', 'trouble_seeing', 'fever', 'body_aches', 'sore_throat', 'sneezing', 'diarrhea', 'rapid_breathing', 'rapid_heart_rate', 'pain_behind_eyes', 'swollen_glands', 'rashes', 'sinus_headache', 'facial_pain', 'shortness_of_breath', 'reduced_smell_and_taste', 'skin_irritation', 'itchiness', 'throbbing_headache', 'confusion', 'back_pain', 'knee_ache', 'prognosis']\n",
      "[INFO] Scaler saved at: C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\\gwo_hho_medican_scaler.pkl\n",
      "[INFO] Running Hybrid GWO + HHO optimization...\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 9ms/step\n",
      "33/33 [==============================] - 1s 5ms/step\n",
      "33/33 [==============================] - 1s 9ms/step\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "33/33 [==============================] - 1s 9ms/step\n",
      "33/33 [==============================] - 1s 9ms/step\n",
      "33/33 [==============================] - 1s 8ms/step\n",
      "[INFO] Iter 1/4 | Best MSE: 0.013425\n",
      "33/33 [==============================] - 1s 8ms/step\n",
      "33/33 [==============================] - 1s 10ms/step\n",
      "33/33 [==============================] - 2s 16ms/step\n",
      "33/33 [==============================] - 1s 11ms/step\n",
      "[INFO] Iter 2/4 | Best MSE: 0.013425\n",
      "33/33 [==============================] - 1s 12ms/step\n",
      "33/33 [==============================] - 1s 4ms/step\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 11ms/step\n",
      "[INFO] Iter 3/4 | Best MSE: 0.013425\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 8ms/step\n",
      "33/33 [==============================] - 1s 10ms/step\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "[INFO] Iter 4/4 | Best MSE: 0.013425\n",
      "[INFO] Best Parameters (lr, dropout, lstm_units): [1.88010711e-03 1.30623367e-01 7.96982050e+01]\n",
      "[INFO] Best MSE: 0.013425\n",
      "Epoch 1/40\n",
      "104/104 [==============================] - 4s 22ms/step - loss: 0.0238 - val_loss: 0.0177\n",
      "Epoch 2/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0181 - val_loss: 0.0158\n",
      "Epoch 3/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0165 - val_loss: 0.0157\n",
      "Epoch 4/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0149 - val_loss: 0.0145\n",
      "Epoch 5/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 6/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0136 - val_loss: 0.0161\n",
      "Epoch 7/40\n",
      "104/104 [==============================] - 2s 18ms/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 8/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0141 - val_loss: 0.0180\n",
      "Epoch 9/40\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0129 - val_loss: 0.0133\n",
      "Epoch 10/40\n",
      "104/104 [==============================] - 2s 18ms/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 11/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 12/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 13/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0120 - val_loss: 0.0136\n",
      "Epoch 14/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 15/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 16/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 17/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 18/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0111 - val_loss: 0.0139\n",
      "Epoch 19/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 20/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0110 - val_loss: 0.0138\n",
      "Epoch 21/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0111 - val_loss: 0.0149\n",
      "Epoch 22/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0112 - val_loss: 0.0140\n",
      "Epoch 23/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0108 - val_loss: 0.0143\n",
      "Epoch 24/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0112 - val_loss: 0.0158\n",
      "Epoch 25/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 26/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 27/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 28/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0107 - val_loss: 0.0144\n",
      "Epoch 29/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0110 - val_loss: 0.0152\n",
      "Epoch 30/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0106 - val_loss: 0.0141\n",
      "Epoch 31/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0098 - val_loss: 0.0144\n",
      "Epoch 32/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 33/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0102 - val_loss: 0.0149\n",
      "Epoch 34/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 35/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0107 - val_loss: 0.0149\n",
      "Epoch 36/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0094 - val_loss: 0.0146\n",
      "Epoch 37/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0101 - val_loss: 0.0146\n",
      "Epoch 38/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0105 - val_loss: 0.0153\n",
      "Epoch 39/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0091 - val_loss: 0.0150\n",
      "Epoch 40/40\n",
      "104/104 [==============================] - 2s 19ms/step - loss: 0.0111 - val_loss: 0.0154\n",
      "[INFO] Model saved at: C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\\gwo_hho_medican_model.keras\n",
      "33/33 [==============================] - 1s 8ms/step\n",
      "[INFO] Metrics: {'MAE': 0.03327126663128953, 'RMSE': 0.12606720163652665, 'R2': 0.5702549205583154}\n",
      "[INFO] Results CSV saved at: C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\\gwo_hho_medican_result.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 195\u001b[39m\n\u001b[32m    192\u001b[39m plt.close()\n\u001b[32m    194\u001b[39m plt.figure()\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m sns.heatmap(\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mActual\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPredicted\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.corr(), annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m\"\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mCorrelation Heatmap\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    197\u001b[39m plt.savefig(os.path.join(visual_dir, \u001b[33m\"\u001b[39m\u001b[33mgwo_hho_medican_heatmap.png\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    662\u001b[39m         raw_lengths.append(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m val.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[32m    667\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIf using all scalar values, you must pass an index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Per-column arrays must each be 1-dimensional"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LSTM, Conv1D, MaxPooling1D, Flatten, concatenate\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“‚ Paths\n",
    "# ============================================================\n",
    "base_path = r\"C:\\Users\\NXTWAVE\\Downloads\\Disease Outbreak Prediction & Health Risk Monitoring System\"\n",
    "data_path = os.path.join(base_path, \"archive\", \"Weather-related disease prediction.csv\")\n",
    "\n",
    "model_path = os.path.join(base_path, \"gwo_hho_medican_model.keras\")\n",
    "scaler_path = os.path.join(base_path, \"gwo_hho_medican_scaler.pkl\")\n",
    "yaml_path = os.path.join(base_path, \"gwo_hho_medican_config.yaml\")\n",
    "json_path = os.path.join(base_path, \"gwo_hho_medican_prediction.json\")\n",
    "csv_path = os.path.join(base_path, \"gwo_hho_medican_result.csv\")\n",
    "visual_dir = os.path.join(base_path, \"visuals\")\n",
    "\n",
    "os.makedirs(visual_dir, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“Š Load & Preprocess Data\n",
    "# ============================================================\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "# Keep numeric columns only\n",
    "df = df.select_dtypes(include=[np.number]).dropna()\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "\n",
    "X = scaled[:, :-1]\n",
    "y = scaled[:, -1]\n",
    "\n",
    "# Split data\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Reshape for CNN-LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"[INFO] Scaler saved at: {scaler_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§  CNN-LSTM Model Builder\n",
    "# ============================================================\n",
    "def create_model(params):\n",
    "    lr, dropout, lstm_units = params\n",
    "    inputs = Input(shape=(X_train.shape[1], 1))\n",
    "\n",
    "    cnn = Conv1D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    cnn = MaxPooling1D(pool_size=2)(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "\n",
    "    lstm = LSTM(int(lstm_units), return_sequences=False)(inputs)\n",
    "    merged = concatenate([cnn, lstm])\n",
    "    dense = Dense(64, activation=\"relu\")(merged)\n",
    "    dense = Dropout(dropout)(dense)\n",
    "    output = Dense(1)(dense)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ¦´ Hybrid GWO + HHO Optimizer\n",
    "# ============================================================\n",
    "def objective_function(params):\n",
    "    lr, dropout, lstm_units = params\n",
    "    model = create_model([lr, dropout, lstm_units])\n",
    "    model.fit(X_train, y_train, epochs=8, batch_size=32, verbose=0)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)\n",
    "\n",
    "def hybrid_gwo_hho(opt_iters=6, pop_size=4):\n",
    "    print(\"[INFO] Running Hybrid GWO + HHO optimization...\")\n",
    "    lb = [1e-4, 0.1, 16]\n",
    "    ub = [1e-2, 0.5, 128]\n",
    "\n",
    "    wolves = np.random.uniform(lb, ub, (pop_size, len(lb)))\n",
    "    fitness = np.array([objective_function(w) for w in wolves])\n",
    "\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best_wolf = wolves[best_idx].copy()\n",
    "    best_score = fitness[best_idx]\n",
    "\n",
    "    for t in range(opt_iters):\n",
    "        a = 2 - t * (2 / opt_iters)\n",
    "        for i in range(pop_size):\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            A = 2 * a * r1 - a\n",
    "            C = 2 * r2\n",
    "            D = abs(C * best_wolf - wolves[i])\n",
    "            new_pos = best_wolf - A * D\n",
    "\n",
    "            E0 = 2 * np.random.rand() - 1\n",
    "            E = 2 * (1 - (t / opt_iters))\n",
    "            if abs(E) >= 1:\n",
    "                new_pos = np.random.uniform(lb, ub)\n",
    "            else:\n",
    "                jump_strength = 2 * (1 - np.random.rand())\n",
    "                new_pos = best_wolf - E * abs(jump_strength * best_wolf - wolves[i])\n",
    "\n",
    "            new_pos = np.clip(new_pos, lb, ub)\n",
    "            new_fit = objective_function(new_pos)\n",
    "            if new_fit < fitness[i]:\n",
    "                fitness[i] = new_fit\n",
    "                wolves[i] = new_pos\n",
    "            if new_fit < best_score:\n",
    "                best_wolf = new_pos.copy()\n",
    "                best_score = new_fit\n",
    "\n",
    "        print(f\"[INFO] Iter {t+1}/{opt_iters} | Best MSE: {best_score:.6f}\")\n",
    "\n",
    "    return best_wolf, best_score\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§© Run Hybrid Optimization\n",
    "# ============================================================\n",
    "best_params, best_score = hybrid_gwo_hho(opt_iters=4, pop_size=4)\n",
    "print(f\"[INFO] Best Parameters (lr, dropout, lstm_units): {best_params}\")\n",
    "print(f\"[INFO] Best MSE: {best_score:.6f}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§  Final Model Training\n",
    "# ============================================================\n",
    "model = create_model(best_params)\n",
    "history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.2, verbose=1)\n",
    "model.save(model_path)\n",
    "print(f\"[INFO] Model saved at: {model_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“ˆ Evaluation\n",
    "# ============================================================\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "try:\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "except TypeError:\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "metrics = {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "print(\"[INFO] Metrics:\", metrics)\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame({\"Actual\": y_test.flatten(), \"Predicted\": y_pred.flatten()})\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"[INFO] Results CSV saved at: {csv_path}\")\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump({\"metrics\": metrics, \"best_params\": [float(x) for x in best_params]}, f, indent=4)\n",
    "\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump({\"optimizer\": \"Hybrid GWO+HHO\", \"best_params\": [float(x) for x in best_params]}, f)\n",
    "\n",
    "# ============================================================\n",
    "# ðŸŽ¨ Visualizations\n",
    "# ============================================================\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.savefig(os.path.join(visual_dir, \"gwo_hho_medican_loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Prediction Comparison\")\n",
    "plt.savefig(os.path.join(visual_dir, \"gwo_hho_medican_comparison_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred}).corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.savefig(os.path.join(visual_dir, \"gwo_hho_medican_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"[âœ…] All outputs saved successfully in:\")\n",
    "print(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0bb01-5342-4a0f-a473-208bd7eb5ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
